{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Extract Images from PDF Documents that Span Across Multiple Pages\n",
        "This notebook contains a series of cells to process images extracted from PDF files. The notebook performs tasks such as installing dependencies, extracting and combining images, and removing duplicate images both locally and in an Azure storage account."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# **Install Dependencies**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 1. Install Dependencies\n",
        "This cell installs all the necessary dependencies using the `requirements.txt` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1736291060131
        }
      },
      "outputs": [],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Example - Extract and Combine Images Locally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "This cell contains three Python functions to:\n",
        "#\n",
        "1. Extract images from a PDF.\n",
        "2. Combine extracted images.\n",
        "3. Extract and combine images from a PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1736292520125
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Function to extract images from PDF\n",
        "def extract_images_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    images = []\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        image_list = page.get_images(full=True)\n",
        "        for img_index, img in enumerate(image_list):\n",
        "            xref = img[0]\n",
        "            base_image = doc.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            images.append((page_num, img_index, image))\n",
        "    return images\n",
        "\n",
        "# Function to combine images vertically\n",
        "def combine_images(images):\n",
        "    widths, heights = zip(*(i.size for i in images))\n",
        "    total_height = sum(heights)\n",
        "    max_width = max(widths)\n",
        "\n",
        "    combined_image = Image.new('RGB', (max_width, total_height))\n",
        "    y_offset = 0\n",
        "    for img in images:\n",
        "        combined_image.paste(img, (0, y_offset))\n",
        "        y_offset += img.height\n",
        "\n",
        "    return combined_image\n",
        "\n",
        "# Main function to extract and combine images from PDF\n",
        "def extract_and_combine_images(pdf_path, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    images = extract_images_from_pdf(pdf_path)\n",
        "    print(\"Number of images:\" +str(len(images)))\n",
        "    current_sequence = []\n",
        "    sequence_count = 1\n",
        "\n",
        "    for i, (page_num, img_index, image) in enumerate(images):\n",
        "        print(\"Page Num\" + str(page_num))\n",
        "        # Assuming images that extend across multiple pages have similar dimensions\n",
        "        if current_sequence and (image.size != current_sequence[-1].size):\n",
        "            combined_image = combine_images(current_sequence)\n",
        "            combined_image.save(f\"{output_folder}/combined_image_{sequence_count}.jpg\")\n",
        "            sequence_count += 1\n",
        "            current_sequence = []\n",
        "        current_sequence.append(image)\n",
        "\n",
        "    if current_sequence:\n",
        "        combined_image = combine_images(current_sequence)\n",
        "        combined_image.save(f\"{output_folder}/combined_image_{sequence_count}.jpg\")\n",
        "\n",
        "    print(f\"Images saved to {output_folder}\")\n",
        "\n",
        "\n",
        "pdf_path = \"input_folder/sample_pdf_with_continued_images_10_pages.pdf\"\n",
        "output_folder = \"output_folder\"\n",
        "extract_and_combine_images(pdf_path, output_folder)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Remove Duplicate Images Locally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "This cell removes duplicate images from the local output folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1736292601588
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#Remove duplicate Image Files\n",
        "\n",
        "import os\n",
        "import hashlib\n",
        "\n",
        "def calculate_hash(image_path):\n",
        "    \"\"\"Calculate the hash of an image.\"\"\"\n",
        "    hasher = hashlib.md5()\n",
        "    with open(image_path, 'rb') as img_file:\n",
        "        buf = img_file.read()\n",
        "        hasher.update(buf)\n",
        "    return hasher.hexdigest()\n",
        "\n",
        "def remove_duplicate_images(folder_path):\n",
        "    \"\"\"Remove duplicate images from a folder.\"\"\"\n",
        "    images_hashes = {}\n",
        "    duplicates = []\n",
        "\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "                image_path = os.path.join(root, file)\n",
        "                image_hash = calculate_hash(image_path)\n",
        "\n",
        "                if image_hash in images_hashes:\n",
        "                    duplicates.append(image_path)\n",
        "                else:\n",
        "                    images_hashes[image_hash] = image_path\n",
        "\n",
        "    # Remove duplicates\n",
        "    for duplicate in duplicates:\n",
        "        os.remove(duplicate)\n",
        "        print(f\"Removed duplicate image: {duplicate}\")\n",
        "\n",
        "folder_path = \"output_folder\"\n",
        "remove_duplicate_images(folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Example - Reading and Writing to Storage Containers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "This cell performs the same tasks as Cell 2 but reads and writes files to an Azure storage account container. The code connects to this storage account using a connection string stored as a secret in Azure Key Vault. Ensure the Azure resource running the notebook has Key Vault Contributor access."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Notes\n",
        "- Ensure you have the necessary permissions to access Azure Key Vault and Storage account.\n",
        "- Modify the paths and storage account details as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1736292423316
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.keyvault.secrets import SecretClient\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "\n",
        "# Define the Key Vault URL and the secret name\n",
        "vault_url = \"https://<VAULT_NAME>.vault.azure.net/\"\n",
        "secret_name = \"<SECRET_NAME>\"\n",
        "\n",
        "# Create a DefaultAzureCredential object\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Create a SecretClient object using the credential\n",
        "client = SecretClient(vault_url=vault_url, credential=credential)\n",
        "\n",
        "# Retrieve the secret\n",
        "connection_string = client.get_secret(secret_name).value\n",
        "\n",
        "# Create a BlobServiceClient object using the connection string\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "\n",
        "container_name = \"data\"\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "\n",
        "# Function to extract images from PDF in blob storage\n",
        "def extract_images_from_pdf(blob_name):\n",
        "    blob_client = container_client.get_blob_client(f\"input_folder/{blob_name}\")\n",
        "    pdf_stream = io.BytesIO()\n",
        "    blob_client.download_blob().readinto(pdf_stream)\n",
        "    pdf_stream.seek(0)  # Reset the stream position to the beginning\n",
        "\n",
        "    doc = fitz.open(stream=pdf_stream, filetype=\"pdf\")\n",
        "    images = []\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        image_list = page.get_images(full=True)\n",
        "        for img_index, img in enumerate(image_list):\n",
        "            xref = img[0]\n",
        "            base_image = doc.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            images.append((page_num, img_index, image))\n",
        "    return images\n",
        "\n",
        "# Function to combine images vertically\n",
        "def combine_images(images):\n",
        "    widths, heights = zip(*(i.size for i in images))\n",
        "    total_height = sum(heights)\n",
        "    max_width = max(widths)\n",
        "\n",
        "    combined_image = Image.new('RGB', (max_width, total_height))\n",
        "    y_offset = 0\n",
        "    for img in images:\n",
        "        combined_image.paste(img, (0, y_offset))\n",
        "        y_offset += img.height\n",
        "\n",
        "    return combined_image\n",
        "\n",
        "# Function to upload image to blob storage\n",
        "def upload_image_to_blob(image, blob_name):\n",
        "    img_byte_arr = io.BytesIO()\n",
        "    image.save(img_byte_arr, format='JPEG')\n",
        "    img_byte_arr = img_byte_arr.getvalue()\n",
        "    blob_client = container_client.get_blob_client(f\"output_folder/{blob_name}\")\n",
        "    blob_client.upload_blob(img_byte_arr, overwrite=True)\n",
        "\n",
        "# Main function to extract and combine images from PDF in blob storage\n",
        "def extract_and_combine_images(blob_name):\n",
        "    images = extract_images_from_pdf(blob_name)\n",
        "    #print(\"Number of images:\", len(images))\n",
        "    current_sequence = []\n",
        "    sequence_count = 1\n",
        "\n",
        "    for i, (page_num, img_index, image) in enumerate(images):\n",
        "        print(\"Page Num:\", page_num)\n",
        "        # Assuming images that extend across multiple pages have similar dimensions\n",
        "        if current_sequence and (image.size != current_sequence[-1].size):\n",
        "            combined_image = combine_images(current_sequence)\n",
        "            output_blob_name = f\"combined_image_{sequence_count}.jpg\"\n",
        "            upload_image_to_blob(combined_image, output_blob_name)\n",
        "            sequence_count += 1\n",
        "            current_sequence = []\n",
        "        current_sequence.append(image)\n",
        "\n",
        "    if current_sequence:\n",
        "        combined_image = combine_images(current_sequence)\n",
        "        output_blob_name = f\"combined_image_{sequence_count}.jpg\"\n",
        "        upload_image_to_blob(combined_image, output_blob_name)\n",
        "\n",
        "    print(f\"Images saved to blob storage container '{container_name}/output_folder'\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "pdf_path = \"sample_pdf_with_continued_images_10_pages.pdf\"\n",
        "extract_and_combine_images(pdf_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Example - Remove Duplicated Images from Output Folder in Storage Container"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "This cell removes duplicate images from the `output_folder` stored in the Azure storage account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1736292447533
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "\n",
        "folder_name = \"output_folder\"\n",
        "\n",
        "# Dictionary to store hashes of images\n",
        "hashes = {}\n",
        "\n",
        "# List blobs in the specified folder\n",
        "blobs_list = container_client.list_blobs(name_starts_with=folder_name)\n",
        "\n",
        "for blob in blobs_list:\n",
        "    blob_client = container_client.get_blob_client(blob)\n",
        "    blob_data = blob_client.download_blob().readall()\n",
        "    \n",
        "    # Calculate the hash of the blob data\n",
        "    blob_hash = hashlib.md5(blob_data).hexdigest()\n",
        "    \n",
        "    if blob_hash in hashes:\n",
        "        # If hash already exists, delete the duplicate blob\n",
        "        print(f\"Deleting duplicate blob: {blob.name}\")\n",
        "        blob_client.delete_blob()\n",
        "    else:\n",
        "        # Store the hash and blob name\n",
        "        hashes[blob_hash] = blob.name\n",
        "\n",
        "print(\"Duplicate images removed.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
